{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is summarization?\n",
    "* A summary is a text that is produced from one or more texts and contains a significant portion of the information in the original text is no longer than half of the original text. \n",
    "\n",
    "### Why Needed?\n",
    "There are basic three phases of document summarization as follows:\n",
    "1) Pre-processing,\n",
    "2) Processing,\n",
    "3) Summary Generation.* A short summary, which conveys the essence of the document, helps in finding relevant information quickly.\n",
    "* Document summarization also provides a way to cluster similar documents and present a summary.\n",
    "\n",
    "### Few Terminologies-\n",
    "*  Indicative vs. informative : used for quick categorization vs. content processing. \n",
    "* Extract vs. abstract :  lists fragments of text vs. re-phrases content coherently. \n",
    "* Generic vs. query-oriented : provides author’s view vs. reflects user’s interest. \n",
    "* Background vs. just-the-news : assumes reader’s prior knowledge is poor vs. up-todate. \n",
    "* Single-document vs. multi-document source :  based on one text vs. fuses together many texts. \n",
    "\n",
    "### Processes Of Document Summarization:\n",
    "There are basic three phases of document summarization as follows:   \n",
    "1) Pre-processing,   \n",
    "2) Processing,   \n",
    "3) Summary Generation.   \n",
    "\n",
    "<img src=\"https://github.com/arijitBhadraMP/MachineLearningAndAI/blob/master/PhasesofDocumentSummarization.jpg?raw=true\">\n",
    "\n",
    "#### Pre-processing\n",
    "Pre-processing is defined here as cleaning the data. For cleaning unwanted characters, symbols, extra spaces, hyperlinks etc are\n",
    "removed. The stop words like ‘a’, ‘the’, ’and’. Stemming is done where the words are reduced to their word root for example\n",
    "‘playing’ would be reduced to ‘play’. Moreover the parsing of the above data is done where the words are bifurcated into nouns,\n",
    "adjectives, verbs etc. The pre-processing is done as per the requirement using one or combination of the above defined\n",
    "techniques.\n",
    "#### Processing\n",
    "This is the next phase of document summarization. After the Text data is cleaned and pre-processed, the processing techniques are\n",
    "applied in which the tf-idf scores, frequency of words are calculated. The data is grouped on the basis of similarity, dissimilarity\n",
    "so that the summary generation can be made efficiently. For this different clustering techniques are used.\n",
    "#### Summary Generation\n",
    "After the data is processed, the summary is to be generated based on the requirement. Extraction of sentences is done from the\n",
    "processed data and the summary is processed. The words to added to sentences, reducing the sentences based on score etc is done\n",
    "in this step to produce summary. The representation of the summary can be in the form of words, sentences, paragraphs, graphs\n",
    "etc. for the summary to be generated different summarizers are used.\n",
    "\n",
    "\n",
    "\n",
    "### Types Of Summarization:\n",
    "Document summarization is mainly divided into following types:\n",
    "<img src=\"https://github.com/arijitBhadraMP/MachineLearningAndAI/blob/master/typesOfSummarizations.jpg?raw=true\">\n",
    "\n",
    "\n",
    "#### Based on types of Approaches\n",
    "There are two type of summarization based on their appraoches.\n",
    "1) Abstractive method\n",
    "Abstractive method builds an internal semantic representation and then uses Natural Language Processing (NLP) to create a\n",
    "summary that is closer to what a human might generate. Such a summary might contain words not explicitly present in the\n",
    "original.    \n",
    "2) Extractive method\n",
    "In extractive summarization selection of a subset of existing words, phrases or sentences in the original text to form a summary is\n",
    "done.\n",
    "#### Based on Number of Input Documents\n",
    "1) Single document\n",
    "The summary of a data from a single document is generated giving the brief idea about the document.\n",
    "2) Multi document\n",
    "The summary from two or more documents is given based on similarity or dissimilarity of the content in the documents.\n",
    "\n",
    "#### Based on Content\n",
    "1) Generic:\n",
    "The generalised summary of the document is given based on the frequency and the importance of the sentence.\n",
    "2) Query-based\n",
    "The summary is generated based on the query from the user about a single topic, word etc.\n",
    "#### Based on Language\n",
    "1) Mono-lingual\n",
    "The summary only for a single language can be generated and it may not give results for other languages.\n",
    "2) Multi-lingual\n",
    "The summarizer can produce summary for multiple languages .\n",
    "#### Based on Domain\n",
    "1) Domain Dependent\n",
    "In this the summary to be produced is dependent on a specific domain and cannot be applied for different domains\n",
    "2) Domain Independent\n",
    "The summaries formed under this category does not depend on any specific domain and the result can be obtained for all the\n",
    "domains.\n",
    "#### Based on Details\n",
    "1) Indicative\n",
    "In the indicative summaries the it mainly gives the main idea about the topic and does not give any other related information\n",
    "available in the document.\n",
    "2) Informative\n",
    "This type of summary gives the details related to the topic along with the important data hence giving more coverage.\n",
    "\n",
    "### Document Summarization Techniques:\n",
    "Term frequency-Inverse document frequency   \n",
    "This technique is used for extraction of word to form the summary.   \n",
    "Tf-Idf of each document is generated using below formula:       \n",
    "Tf-Idf t,d = Tf t,d ∗ Idf t        \n",
    "Where Tf is term frequency of term t in document d and      \n",
    "Idf t =log(N/df t )      \n",
    "Where N is the number of documents in corpus and         \n",
    "df is the document frequency of t.         \n",
    "#### 1) Cluster based:\n",
    "In this technique the sentences or words are clustered on the basis of similarity or dissimilarity and the data is extracted from each\n",
    "cluster to form the summary of that cluster. Different clustering techniques like k-means, hierarchical clustering etc are used\n",
    "#### 2) Graph theoretic :\n",
    "In this technique the sentences or words are represented in the form of nodes of a unidirectional graph. This method gives the\n",
    "idea about the coverage about a specific sentence or word and also the most important once can be extracted on the basis of high\n",
    "cardinality.\n",
    "#### 3) Classification:\n",
    "The data is classified into multiple classes as per the requirement. The data from the specific class can be extracted. Again this is a\n",
    "extraction technique for document summarization. Decision tree, rule based, support vector machine, k-nearest neighbour are\n",
    "various classification techniques used.\n",
    "#### 4) Neural network:\n",
    "In neural networks, the information is processed in a similar way to te human brain. Initially it learns about all the features which\n",
    "must be present in the sentence, and then extracts them on the basis of it, removes dissimilar features and merges the similar ones.\n",
    "#### 5) Ontology based:\n",
    "This is a abstraction based technique where the dictionary of words is used for the summarization process.\n",
    "#### 6) Fuzzy logic based:\n",
    "In this summarization technique, instead of binary output the output is obtained in n-ary form.\n",
    "#### 7) Sematic based:\n",
    "This summarization technique uses the semantic analysis abstraction method to generate summaries which are more accurate like\n",
    "the human generated summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
